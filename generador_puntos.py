import ee
import os
import json
import pandas as pd
import sys

# --- 1. AUTENTICACI√ìN ROB√ìTICA ---
print("ü§ñ Iniciando Generador de Puntos Aut√≥nomo...")

try:
    # Intentamos leer el secreto desde las variables de entorno (GitHub Actions)
    secreto = os.environ.get('EE_SECRET_JSON')
    
    if secreto:
        # Estamos en la nube (GitHub)
        credenciales_dict = json.loads(secreto)
        credenciales = ee.ServiceAccountCredentials(None, key_data=json.dumps(credenciales_dict))
    else:
        # Estamos en local (PC) - Intentamos buscar el archivo json
        # CAMBIA ESTO SI TU ARCHIVO TIENE OTRO NOMBRE
        if os.path.exists('llave-secreta.json'):
            credenciales = ee.ServiceAccountCredentials(None, key_file='llave-secreta.json')
        else:
            raise Exception("No se encontr√≥ llave de autenticaci√≥n (ni entorno ni archivo).")

    ee.Initialize(credenciales)
    print("‚úÖ Conexi√≥n con Earth Engine exitosa.")

except Exception as e:
    print(f"‚ùå Error cr√≠tico de autenticaci√≥n: {e}")
    sys.exit(1)

# --- 2. CONFIGURACI√ìN GEOGR√ÅFICA ---
# Definimos Antioquia (o tu zona de inter√©s)
ROI = ee.FeatureCollection("FAO/GAUL/2015/level1")\
    .filter(ee.Filter.eq('ADM1_NAME', 'Antioquia'))

# Si quieres usar el CSV local para entrenar, aseg√∫rate de que 'ant.csv' est√© en el repo
# Si no est√°, usaremos datos sint√©ticos o globales para no romper el script
TIENE_DATOS_LOCALES = os.path.exists('ant.csv')

# --- 3. EL MODELO (Versi√≥n Compacta) ---
def obtener_variables(roi):
    # Modelo digital de elevaci√≥n
    dem = ee.Image("USGS/SRTMGL1_003").clip(roi)
    pendiente = ee.Terrain.slope(dem)
    
    # Lluvia hist√≥rica (CHIRPS) - Promedio anual
    lluvia = ee.ImageCollection("UCSB-CHG/CHIRPS/PENTAD")\
        .filterDate('2020-01-01', '2021-01-01')\
        .select('precipitation').mean().clip(roi)
    
    # NDVI (Vegetaci√≥n)
    l8 = ee.ImageCollection("LANDSAT/LC08/C02/T1_L2")\
        .filterBounds(roi)\
        .filterDate('2023-01-01', '2024-01-01')\
        .median().clip(roi)
    
    ndvi = l8.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')
    
    # Stack final (Apilamos las capas)
    stack = dem.rename('elevation')\
        .addBands(pendiente.rename('slope'))\
        .addBands(lluvia.rename('rain'))\
        .addBands(ndvi)
        
    return stack

try:
    print("üì° Descargando variables satelitales...")
    stack = obtener_variables(ROI)
    
    # --- 4. ENTRENAMIENTO (L√≥gica Simplificada para Automatizaci√≥n) ---
    # Aqu√≠ es donde el robot aprende. 
    # Para producci√≥n, idealmente cargar√≠as un CSV 'ant.csv' del repositorio.
    
    puntos_entrenamiento = None
    
    if TIENE_DATOS_LOCALES:
        print("üìÇ Usando base de datos local 'ant.csv'...")
        df = pd.read_csv('ant.csv', sep=';', on_bad_lines='skip', encoding='latin-1')
        
        # Limpieza r√°pida (igual que en Colab)
        def limpiar(val):
            try: return float(str(val).replace(',', '.'))
            except: return None
            
        df['lat'] = df['NORTE'].apply(limpiar)
        df['lon'] = df['ESTE'].apply(limpiar)
        df = df.dropna(subset=['lat', 'lon'])
        
        # Convertir a GEE
        features = []
        for _, row in df.head(500).iterrows(): # Limitamos para velocidad
            geom = ee.Geometry.Point([row['lon'], row['lat']])
            features.append(ee.Feature(geom, {'class': 1}))
            
        positivos = ee.FeatureCollection(features)
        
        # Negativos (Zonas seguras aleatorias)
        negativos = ee.FeatureCollection.randomPoints(ROI.geometry(), 500).map(lambda f: f.set('class', 0))
        puntos_entrenamiento = positivos.merge(negativos)
        
    else:
        print("‚ö†Ô∏è No se encontr√≥ 'ant.csv'. Usando datos globales NASA (Fallback)...")
        # Fallback si no subiste el csv al repo
        nasa = ee.FeatureCollection("projects/google/GLC").filterBounds(ROI)
        positivos = nasa.map(lambda f: f.set('class', 1))
        negativos = ee.FeatureCollection.randomPoints(ROI.geometry(), positivos.size()).map(lambda f: f.set('class', 0))
        puntos_entrenamiento = positivos.merge(negativos)

    print(f"üß† Entrenando modelo con {puntos_entrenamiento.size().getInfo()} puntos...")
    
    # Extraer valores para entrenar
    training_data = stack.sampleRegions(
        collection=puntos_entrenamiento,
        properties=['class'],
        scale=100, # Escala 100m para rapidez en GitHub Actions
        tileScale=16,
        geometries=True
    )
    
    # Random Forest
    rf = ee.Classifier.smileRandomForest(50).train(
        features=training_data,
        classProperty='class',
        inputProperties=stack.bandNames()
    )
    
    # Clasificar
    print("üó∫Ô∏è Generando mapa de riesgo...")
    susceptibilidad = stack.classify(rf.setOutputMode('PROBABILITY'))
    
    # --- 5. EXTRACCI√ìN DE PUNTOS CENTINELA ---
    print("üêï Extrayendo los 50 puntos m√°s cr√≠ticos...")
    
    # Estrategia 'Sabueso' simplificada
    puntos_criticos = susceptibilidad.gt(0.7).selfMask() # Solo riesgo alto
    
    muestras = puntos_criticos.stratifiedSample(
        numPoints=50,
        classBand='classification',
        region=ROI.geometry(),
        scale=500,
        geometries=True,
        dropNulls=True
    )
    
    # Guardar a CSV
    datos = muestras.getInfo()
    lista_final = []
    
    if 'features' in datos:
        for f in datos['features']:
            coords = f['geometry']['coordinates']
            lista_final.append({
                'lat': coords[1],
                'lon': coords[0],
                'susc_modelada': f['properties'].get('classification', 0.99)
            })
            
    df_export = pd.DataFrame(lista_final)
    df_export.to_csv('puntos_monitoreo.csv', index=False)
    
    print(f"‚úÖ ¬°√âXITO! Se gener√≥ 'puntos_monitoreo.csv' con {len(df_export)} puntos.")

except Exception as e:
    print(f"‚ùå Error en el proceso de modelado: {e}")
    sys.exit(1)
